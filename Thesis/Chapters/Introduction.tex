\chapter{Introduction}
%\addcontentsline{toc}{chapter}{1. Introduction}

The vast majority of people imagine music. 
Imagining music can be defined as a deliberate internal recreation of the perceptual experience of listening to music \cite{schaefer_name_2011}.
Individuals can imagine themselves producing music, imagine listening to others produce music, or simply ``hear'' the music in their heads. 
Music imagination is used by musicians to memorize music, and anyone who has ever had an ``ear-worm'' -- a tune stuck in their head -- has experienced imagining music. 
Because of its simplicity, no training is required to imagine a song, and researchers have therefore been investigating the utility of music imagery for \acp{BCI}.
A \ac{BCI} is a system that allows an external device to be controlled or modified using brain activity. 
Music imagery appears to be a very promising means for driving \acp{BCI} that use \ac{EEG} -- a popular non-invasive neuroimaging technique that relies on electrodes placed on the scalp to measure the electrical activity of the brain.
For instance, Schaefer \etal\citeyear{schaefer_measuring_2011} argue that
\emph{``music is especially suitable to use here as (externally or internally generated) stimulus material, since it unfolds over time, and \ac{EEG} is especially precise in measuring the timing of a response.''}
For patients that have difficulties communicating behaviourally (e.g., patients with locked-in syndrome), \ac{BCI}s are a promising communication tool. 
{BCI}s that currently exist are generally binary systems that allow the user to choose between two options to answer yes/no questions \cite{Monti2010}.
A system with a larger number of options would allow for a more complete and efficient communication experience. 
Using music as the basis for a \ac{BCI} is a promising way to build such a system because of the large number of musical pieces that exist. 
Ideally, a music-based \ac{BCI} would allow the user to imagine a piece of music to convey a particular thought. 
However, the translation from music imagination will require careful processing of the EEG data. 

EEG data contain a variety of signals (elicited by external stimuli like sounds, lights etc.) that can be exploited by a \ac{BCI}. 
For a \ac{BCI} to be successful, it must be able to distinguish between different induced brain states. 
Perceived rhythmic sequences have been shown to alter \ac{EEG} signals resulting in unique brain states.
It has been shown that oscillatory neural activity in the gamma frequency band (20-60 Hz) is sensitive to accented tones in a rhythmic sequence \cite{snyder_gamma-band_2005}.
Oscillations in the beta band (20-30 Hz) entrain to rhythmic sequences \cite{cirelli_beta_2014, merchant_beta_2015} and increase in anticipation of strong tones in a non-isochronous, rhythmic sequence \cite{iversen_top-down_2009,fujioka_beta_2009,fujioka_internalized_2012}.
The magnitude of \acp{SSEP}, which reflect neural oscillations entrained to the stimulus, increases in frequencies related to the metrical structure of the rhythm when subjects hear rhythmic sequences.
%This is a sign of neural entrainment to beat and meter \cite{nozaradan_tagging_2011,nozaradan_selective_2012}, which are the nested structures of intervals between the sounds in a rhythm. 
%The beat is the basic pulse of the rhythm that one might tap their foot to, and these beats can be grouped to create meter; generally into groups of three of four beats. 
In addition, perturbations of the rhythmic pattern lead to distinguishable \acp{ERP} \cite{geiser_early_2009, vlek_shared_2011}.
It is also possible to detect imagined auditory accents imposed over a steady metronome click from EEG \cite{nozaradan_tagging_2011}.
Finally, \ac{EEG} signals have been used to distinguish between perceived rhythmic stimuli \cite{stober2014nips}.
Thus, rhythm alters \ac{EEG} patterns in systematic ways that may be exploited by a \ac{BCI}. 
Because rhythm is an inherent part of music, we expect music to have a similar effect on \ac{EEG} signals. 

EEG has already successfully been used to classify perceived melodies. 
In a study by Schaefer \etal \citeyear{schaefer_name_2011}, 10 participants listened to 7 short melody clips 3-4 seconds long.
Each stimulus was presented 140 times in randomized back-to-back sequences of all stimuli.
The classification accuracy varied between 25\% and 70\% within subjects.
Applying the same classification scheme across participants, they obtained between 35\% and 53\% accuracy.

Recently, studies have identified an overlap between the brain areas that are active during the imagination and the perception of music \cite{halpern_fmri_2004,Kraemer2005,Herholz2008,herholz_2012}. 
Knowing that it is possible to classify perceived music stimuli from EEG, and that there is an overlap in brain areas active during music perception and imagination, we therefore sought to examine \ac{EEG} data collected while participants listen to melodies to learn about the neural responses during music perception, and determine which salient elements are to be expected during music imagination.
Exploring EEG data during music perception could inform how we approach music imagination data, and the brain signals recorded while listening to music could serve as reference data for decoding music imagination. 
This is particularly relevant to developing an effective \ac{BCI} because of the need for training both the system and the user.
The user needs to learn how to effectively modify brain states in a way that the system can understand, and the system needs to learn to recognize the different brain states of the unique user.
By using perception data to train a \ac{BCI} we cut down on the amount of imagination training needed, which will reduce potential user fatigue.

Brain activity induced by music imagination has also been detected by \ac{EEG} \cite{schaefer_shared_2013}, and encouraging preliminary results for classifying imagined music fragments from \ac{EEG} recordings were reported in Schaefer \etal \citeyear{schaefer_single_2009} in which 4 out of 8 participants produced imagery that was classifiable. 
In this experiment participants imagined four different musical phrases, but classification was done within pairs of stimuli.
The best results in a single pair of stimuli showed an accuracy between 70\% and 90\% after 11 repetitions of the imagined musical phrase. 

Although \ac{EEG} has been used to decode music imagination, the accuracy levels were not robust enough for these decoding techniques to be used in a \ac{BCI}. 
Basic EEG processing methods may not have the sensitivity to detect the subtle changes that occur during music imagination. 
However, sophisticated processing techniques, such as those used in machine learning, may be more suited to this challenge. 

Machine learning is a method that produces algorithms that can learn from and make predictions about data.
For example, the programs used by postal services to recognize handwriting on envelopes or the speech recognition software in your cell phone are based on machine learning techniques.
One such technique uses \acp{ANN}.
\acp{ANN} were inspired by the powerfully complex visual system found in humans and other animals.
In the retina, cells respond to small regions of the visual field called receptive fields \cite{Kalat2008}. 
As information moves along the visual processing stream, single cells in higher layers receive input from multiple cells in lower layers.
At each level, more information is combined, giving cells higher up in the processing stream an increasingly global view of the information collected by the retinal cells (i.e., what the retinal cells are `seeing').
Complex visual information is processed farther along the processing stream than simple information as cells in these far layers are sent information from a larger number of retinal cells.
For example, when looking at a house, information about edges and colour are processed at lower levels.
Information from multiple low-level cells is combined and passed to high-level cells that process more global information like shape. 
The recognition of the full object as being a house occurs at the highest level in the stream. 
\acp{ANN} work in a similar way to process complex data. 
The processing units in a neural network act like cells in the visual system.
The ``receptive field'' of each one of these units is determined by a filter, which can be thought of as a pattern of weights.
Each filter is created based on a variety of parameters set by the researcher, or determined by the network during the training process.
The filters in each subsequent layer of the network `see' larger amounts of the original input data, and the input is classified in the final layer of the network. 
Before a neural network can be used to classify data it must learn the characteristics of the data. 
Through backpropagation, the layers of the model were trained to optimize the outcome. 
In our model, the filters were optimized to produce the best classification results.
The optimized filters are applied to new data and the accuracy of the classification is determined. 
In this study, a neural network is used to classify music stimuli from brain data collected during music perception and imagination. 

To classify our music stimuli from EEG data we first tried an ERP analysis, using \ac{PCA}, similar to that of Schaefer \etal\citeyear{schaefer_name_2011} to determine which piece of music a participant was listening to or imagining.
In this experiment, we collected fewer trials per stimulus and therefore had much less data than Schaefer \etal\citeyear{schaefer_name_2011}. 
As a result, the ERP analysis proved unsuccessful, so we used a neural network to detect more complex characteristics of the music from EEG that would better allow us to classify stimuli.
Using this technique we were able to classify perception of 12 music pieces with a 29.6\% accuracy rate (chance = 17.59\%) at a significance level of p=0.001.
Using this same technique we were unable to accurately classify imagination of music (accuracy = 7.41\%). 