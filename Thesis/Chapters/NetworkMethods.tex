\chapter{Neural Network}
Schaefer \etal \citeyear{schaefer_name_2011} were able to use the unique time course of the component responsible for the most variance to differentiate between stimuli.
With our components we were unable to reproduce this stimulus classification accuracy. 
 
To classify our data, we used a technique from the computer science called an artificial neural network (\ac{ANN}).
A neural network contains one or more layers that process the data.
In these layers, the input is processed by a filter (weight matrix) that is trained using backpropagation \cite{Rumelhart_backpropagation_1986}. 
Our network was optimized for our stimulus classification task and included three processing layers.
The full explanation of how we arrived at the best model can be found in \cite{stober_ICLR2016} (arXiv:1511.04306).

\section{Layer 1: Similarity Constraint Encoding}
The first layer was pre-trained on the perception data using 432 trials (9 subjects x 12 stimuli x 4 trials) and then was not changed during training of the full 3-layer model. 
One trial of each stimulus from each subject's data was left out to be used as the test set for later model testing (108 trials (9 subjects x 12 stimuli x 1 trial) ).
%Techniques such as \ac{PCA} and \ac{ICA} can be used to find stable and representative patterns (or components) in the \ac{EEG} data.
%Another way to learn such patterns is by using \acp{CAE}.
%\acp{CAE} are a special variant of \acp{CNN} that encode their input using convolution into a compressed internal representation which is then decoded using de-convolution into the original space trying to minimize the reconstruction error. 
%Using \acp{CAE} allows us to learn individually adapted components that are linked between subjects.
We wanted to find features in the data that were stable across trials and subjects, and also distinguished between classes. 
To identify such features, we used a pre-training strategy called \emph{similarity-constraint encoding}.
% in which the \ac{CAE} is trained to encode relative similarity constraints. 
As introduced by Schultz and Joachims \citeyear{schultz_learning_2004}, a relative similarity constraint $(a,b,c)$ describes a relative comparison of the trials $a$, $b$, and $c$ in the form ``$a$ is more similar to $b$ than $a$ is to $c$.''
Here, $a$ is the reference trial used for this comparison, $b$ is a trial from the same stimulus, and $c$ is a trial from another stimulus.
The number of violated constraints is used as a cost function for learning features of the data that are important for stimulus classification. 
A cost function describes the characteristics of the system that we want to minimize -- in this case we want to minimize the number of violations to the similarity constraint.
The number of violated constraints is minimized using the standard backpropagation training technique used for artificial neural networks.
To this end, we combined all pairs of trials $(a,b)$ from the same stimulus with all trials $c$ from other stimuli and told the system that $a$ and $b$ must be more similar.
For example, we created all possible pairs of trials from the perception of Jingle Bells with lyrics and then combined each of those pairs with all other perception trials.
Each one of these triplets was then processed by the \ac{SCE}. % (under the similarity constraint).
In this way, the system learned features (signal components) that result in high similarities between trials from the same stimulus and differences between trials from different stimuli.  
The spatial representation of the features learned by this \ac{SCE} is visualized in Layer 1 of \autoref{fig:model_W}. 
The coloured areas represent the regions and the electrode weightings that the encoder has determined are optimal for differentiating stimuli.
This representation acts as a spatial filter that processes the raw data.
The 64 EEG channels are reduced to a single data stream of weighted EEG by this filter\footnote{After being processed by the spatial filter we applied a non-linear activation function to the data (a step which generally occurs in all neural network layers).
We used the tanh function here.}. 
\begin{figure}[h] 
  \begin{center}
    \includegraphics[width=\textwidth,keepaspectratio=true]{Figures/model_W}
%   \\\vspace{-0.8em}
    \caption{Visualization of our neural network, which processes raw EEG at a sampling rate of 512\,Hz.
    Layer 1 was pre-trained using similarity-constraint encoding and is a spatial representation of EEG electrode weights. Layer 2 is a 37 sample long temporal filter. Layer 3 shows the compressed representations of the raw EEG data. The numbers are the ID numbers of the stimuli found in \autoref{tab:stimuli_information}. The colours are an indication of the weighting decided on by the model. We can interpret the intense red and blue colours as being more important for stimulus classification than the white areas.}
    \label{fig:model_W}
  \end{center}
%  \vspace{-1em}
\end{figure}
\section{Layer 2: Temporal Filter \& Layer 3: Templates}
Layers two and three were trained together with supervised learning and optimized by back propagation through the entire model with a cost function to minimize classification error.
The single data stream output from layer one entered the second layer where it was convolved with a filter and pooled with a subsampling factor of 11.
This produced a compressed representation of the original EEG data.

To find the optimal parameters (learning rate, filter size, etc.) for our neural network, we employed a 9-fold cross validation scheme by training on the data from 9 subjects (384 trials) and validating on the remaining subject (48 trials).
The cross-validation was done within the training set. %This process created optimized, compressed representations of the EEG data for each stimuli.
The final versions of layer 2 and 3 seen in \autoref{fig:model_W} are an average of the model parameters over all 9 folds.
Layer 2 is the filter that processes the data stream from layer 1, and layer 3 is made up of the optimized, compressed representations of the original EEG data for each stimulus.
\section{Full model explanation}
The classification accuracy of the model was then tested with the test set of 108 trials. 
Each trial in the test set was processed by the filters in layer 1 and layer 2. 
The resulting compressed representation (the output from layer 2) of the test trial was compared against each of the optimized representations in layer 3 of the model.
The dot product of the test trial's representation was taken with each of the optimized layer 3 representations.
This produced 12 values (one for each stimulus) that described the similarity of the test trial's representation with each of the optimized representations. 
The test trial was given the label of the stimulus whose representation it matched the most, i.e., the highest similarity value from the dot product. 